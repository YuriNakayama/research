# **包括的調査報告書：モデル非依存型因果効果推定（アップリフトモデリング）の数理と最新動向 (2023-2025)**

## **1\. 序論：因果推論の実務的転換とモデル非依存性の重要性**

### **1.1 背景：相関から因果へのパラダイムシフト**

現代のデータサイエンス、特にデジタルマーケティング、医療統計、公共政策の分野において、分析の主眼は「何が起きるか（予測）」から「何をすれば結果が変わるか（介入）」へと急速に移行している。従来の予測モデリング（Predictive Modeling）は、観測された特徴量とアウトカムの相関関係を学習し、将来のイベント発生確率を算出することに長けていた。しかし、例えば「離反しそうな顧客」を高精度に特定できたとしても、「どのような介入（クーポン配布、電話勧誘、メール配信など）を行えば離反を防げるか」という問いには答えられない。

ここで必要となるのが、**因果推論（Causal Inference）**、とりわけ個々の対象に対する介入効果の異質性を推定する **CATE（Conditional Average Treatment Effect）** の推定技術である。実務的には **アップリフトモデリング（Uplift Modeling）** と呼ばれるこの分野は、個体 $i$ に対する処置 $W$ の効果 $\\tau\_i$ を推定し、効果が最大となる層（Persuadables）への資源集中や、逆効果となる層（Sleeping Dogs）への介入回避を可能にする。

### **1.2 モデル非依存型（Model-Agnostic）アプローチの定義と意義**

CATE推定の手法は多岐にわたるが、近年特に注目されているのが「モデル非依存型（Model-Agnostic）」のアプローチである。これは、因果効果の推定を特定のアルゴリズム（例：Causal Forestのような特定の分割基準を持つ決定木や、特定のニューラルネットワーク構造）に依存させず、**データの前処理（変換）や損失関数の工夫によって、任意の教師あり学習アルゴリズムを因果推論器として転用する** 手法の総称である。

本調査が対象とする「機械学習モデルを選ばない」手法群は、以下の実務的・理論的メリットを持つ。

1. **最新アルゴリズムの即時適用:** ベースとなる学習器（Base Learner）として、その時点で最先端の予測モデル（例：XGBoost, LightGBM, CatBoostなど）を自由に選択できる。これにより、予測モデル分野での計算高速化や正則化技術の恩恵を直接享受できる。  
2. **実装の柔軟性と保守性:** 特殊なカスタムモデルを実装・運用するコストを削減し、既存のMLパイプライン（scikit-learn準拠のインターフェースなど）に「変換ステップ」を組み込むだけで導入可能である。  
3. **多様なデータ形式への対応:** テーブルデータだけでなく、テキストや画像を含むデータであっても、それらを処理可能なベース学習器を選択することで、因果推論の枠組みを維持したまま対応できる。

### **1.3 本報告書の構成と調査範囲**

本報告書は、2023年から2025年にかけて発表された英語論文を中心に、モデル非依存型アップリフトモデリングの最前線を調査したものである。特に、ユーザーの要求に基づき、以下の領域に焦点を当てる。

* **クラス変数変換（Class Variable Transformation: CVT）とその拡張:** 従来のLaiの手法やJaskowskiの手法を出発点とし、ゼロアウトカム情報の活用やクラス不均衡への対処を行う最新手法（Li & Zhu, 2024; Nyberg, 2024等）。  
* **アウトカム変換（Outcome Transformation）の高度化:** 連続値アウトカムや連続的処置（Continuous Treatment）への適応（De Vos, 2024等）、および操作変数（Instrumental Variable）を用いたモデル非依存的アプローチ。  
* **直接最適化（Direct Optimization）とカスタム損失関数:** XGBoostやLightGBMの目的関数をハックし、変換を行わずに直接CATEを最大化する実務的手法。

なお、Neural Network、Causal Forest、S/T/X-Learner等のMeta-Learner、およびプライバシー保護技術については、調査対象外とする。

## ---

**2\. 理論的枠組み：Rubin因果モデルと変換アプローチ**

### **2.1 潜在的結果変数（Potential Outcomes）フレームワーク**

本報告書におけるすべての議論は、Rubin因果モデル（RCM）に基づく。  
個体 $i$ において、処置を受けた場合の結果を $Y\_i(1)$、受けなかった場合の結果を $Y\_i(0)$ とする。観測される結果 $Y\_i$ は、実際の処置割付 $W\_i \\in \\{0, 1\\}$ によって以下のように定まる。

$$Y\_i \= W\_i Y\_i(1) \+ (1 \- W\_i) Y\_i(0)$$  
ここで、個体レベルの因果効果（ITE）は $\\tau\_i \= Y\_i(1) \- Y\_i(0)$ であるが、「因果推論の基本問題」により $Y\_i(1)$ と $Y\_i(0)$ の片方しか観測できないため、直接算出は不可能である。  
したがって、特徴量 $X\_i$ で条件付けた平均処置効果（CATE）の推定が目標となる。

$$\\tau(x) \= E$$

### **2.2 変換アプローチ（Transformation Approaches）の基本原理**

モデル非依存型手法の核心は、観測データ $(X\_i, W\_i, Y\_i)$ を新たなターゲット変数 $Z\_i$（または $Y\_i^\*$）に変換し、その条件付き期待値 $E\[Z\_i | X\_i\]$ が $\\tau(x)$ と線形関係を持つように設計することにある。

$$E\[Z\_i | X\_i\] \= a \\cdot \\tau(x) \+ b$$  
この関係式が成立すれば、回帰や分類の問題として $\\hat{Z} \= f(X)$ を学習することで、$\\hat{\\tau}(x) \= (\\hat{Z} \- b) / a$ としてCATEを復元できる。この「変換」の設計こそが、近年の研究の主戦場である。

## ---

**3\. クラス変数変換（CVT）の最前線：不均衡と情報の損失への挑戦**

クラス変数変換（CVT: Class Variable Transformation）は、ターゲット変数 $Y$（通常は二値）と処置変数 $W$ を組み合わせて新たなクラスラベル $Z$ を生成する手法である。2023年以降の研究は、古典的なCVTが抱える「情報の損失」と「クラス不均衡への脆弱性」を克服する方向に進んでいる。

### **3.1 古典的手法の再考**

最新手法を理解するために、基礎となる2つの古典的アプローチを定義する。

#### **3.1.1 Lai's Method (2006) の限界**

Laiの手法は、顧客を「処置成功群 (TR)」と「対照失敗群 (CN)」をポジティブクラス ($Z=1$)、「処置失敗群 (TN)」と「対照成功群 (CR)」をネガティブクラス ($Z=0$) に分類する。

| グループ | 処置 W | 結果 Y | 新ラベル ZLai​ | 意味 |
| :---- | :---- | :---- | :---- | :---- |
| Treatment Responder (TR) | 1 | 1 | **1** | 処置で成功（望ましい） |
| Control Non-responder (CN) | 0 | 0 | **1** | 放置で失敗（処置すべきだったかも） |
| Treatment Non-responder (TN) | 1 | 0 | 0 | 処置で失敗（無駄） |
| Control Responder (CR) | 0 | 1 | 0 | 放置で成功（処置不要） |

この手法は直感的であるが、数学的には $P(W=1) \\neq 0.5$ の場合にバイアスが生じることが知られている 1。

#### **3.1.2 Jaskowski & Jaroszewicz (2012) の Z変換**

Laiの手法を厳密化したのが、Jaskowskiらのアプローチである。

$$Z \= Y \\cdot W \+ (1 \- Y)(1 \- W)$$  
$P(W=1)=0.5$（ランダム化比較試験で均等割付）の仮定下で、以下の関係が成立する。

$$2P(Z=1|X) \- 1 \= \\tau(X)$$

これにより、任意の分類器（Logistic Regression, SVM, Random Forestなど）で $P(Z=1|X)$ を予測するだけでCATEが推定可能となる 2。しかし、この手法には重大な欠点がある。「処置して失敗 ($W=1, Y=0$)」と「処置せず成功 ($W=0, Y=1$)」という、本来全く異なる意味を持つ事象が、共に $Z=0$ にマッピングされてしまう点である。これは情報の損失を意味する。

### **3.2**

3 Li & Zhu (2024): 新規変換アプローチ (A New Transformation Approach)

2024年にLiとZhuによって提案されたこの手法は、CVTにおける「ゼロアウトカム情報の損失」問題に対処する画期的なアプローチである。

#### **3.2.1 問題の所在：スパースな正例と情報の埋没**

マーケティングや医療のデータでは、コンバージョン（$Y=1$）は稀なイベントであることが多い。従来のCVTでは、圧倒的多数を占める「処置して失敗 ($W=1, Y=0$)」と「処置せず失敗 ($W=0, Y=0$)」が、それぞれ $Z=0$ と $Z=1$ に割り振られる。  
特に問題なのは、$Y=0$ のサンプルが大量にある中で、処置変数 $W$ の情報が $Z$ の定義に埋没してしまうことである。Liらは、従来の $Z$ 変換が $Y=0$ のサンプルにおける $W$ の差異を十分に活用できていないと指摘した 3。

#### **3.2.2 手法のメカニズム**

Li & Zhuのアプローチは、ゼロアウトカム ($Y=0$) を持つサンプルに対して、単なるラベル割り当て以上の情報を付与する新たな変換変数 $Z^\*$ を導入する。  
論文の記述 3 によると、彼らは以下のような特性を持つ変換を設計している。

1. **ゼロアウトカムの価値化:** 従来法ではノイズとして扱われがちな $Y=0$ のサンプル群において、処置 $W$ の有無が将来的なポテンシャルにどう影響するかを数理的に組み込む。  
2. **不均衡への耐性:** $Y=1$ が少ない場合でも、変換後の $Z^\*$ の分布が極端に偏らないように調整されており、学習の安定性が高い。

具体的な変換式（推論含む）は、従来の $Z$ に対し、全体のコンバージョン率や処置割付比率に応じた重み付け項 $\\delta$ を導入した形となる。

$$Z^\*\_i \= f(Y\_i, W\_i, \\hat{p}(X\_i))$$

実験では、XGBoostをベース学習器として使用し、中国の金融機関の大規模データセットにおいて、従来のCVT（Jaskowski法）と比較してAUUC（Area Under Uplift Curve）およびQini係数で有意な改善を示している 3。  
インサイト:  
この研究は、「アップリフト＝反応率の差」という単純な図式を超え、「反応しなかった場合の処置の重み」をどう扱うかが精度向上の鍵であることを示唆している。特に金融商品のような低コンバージョン商材において、このアプローチは標準的な選択肢となり得る。

### **3.3**

5 Nyberg (2024): クラス反転法 (Class Flipping)

Oskar Nybergらによる2024年の研究は、CVTモデルの実装における最大の障壁である「クラス不均衡問題」に対する決定的な解法を提案している。

#### **3.3.1 CVTの不均衡脆弱性**

CVTモデルにおいて、ターゲット変数 $Z$ の平均値 $P(Z=1)$ は、元のデータのコンバージョン率 $P(Y=1)$ と処置割付 $P(W=1)$ に依存する。もし $Y=1$ が極めて稀（例えば0.1%）であれば、$Z=1$ となる確率も極めて低くなる（または $Z=0$ に偏る）。  
通常の分類器は、クラス不均衡が激しい場合、すべてを多数派クラス（Majority Class）と予測する「自明なモデル（Trivial Model）」に収束しやすい。アップリフトモデリングにおいてこれは致命的であり、CATEが全員ゼロと予測されてしまう。

#### **3.3.2 Class Flippingのアルゴリズム**

Nybergらは、対照群（Control Group）のクラスラベルを確率的に反転させることで、人工的にバランスの取れたデータセットを作成し、その上でCATEを推定する手法を開発した 5。

**手順:**

1. **反転 (Flipping):** 対照群 ($W=0$) のデータにおいて、観測されたクラス $Y$ を確率 $k$ で反転させる（または決定論的に $1-Y$ とする）。  
2. **結合 (Concatenation):** 反転させた対照群データを処置群データと結合する。  
3. **再重み付け (Reweighting):** 反転操作によって歪んだ確率分布を補正するため、各サンプルに重み $w\_i$ を付与する。この重みは、処置割付確率 $e(X)$ と反転確率 $k$ から逆算される。

$$\\text{Target } \\tilde{Y} \= \\begin{cases} Y & \\text{if } W=1 \\\\ 1-Y & \\text{if } W=0 \\end{cases}$$  
この変換を行ったデータセットで $P(\\tilde{Y}=1|X)$ を予測すると、その予測値は（適切なスケーリングの後）CATEと正の相関を持つことが証明される。

重要な発見:  
Nybergらは、この手法を用いることで、アンダーサンプリングのような情報損失を伴う手法を使わずとも、極端な不均衡データ（Imbalanced RCT Data）においてCVTモデルがS-LearnerやT-Learnerを凌駕する性能を発揮できる ことを示した。これは、CVTが「古い手法」ではなく、適切な前処理と組み合わせることで最強のモデルになり得ることを示唆している。

### **3.4**

7 Vairetti (2024): オーバーサンプリングとマッチング

Carla Vairettiらは、不均衡への対処として、データレベルの操作に焦点を当てた。  
彼女らのアプローチは、CVT変換を行う前に、処置群と対照群の特徴量分布をマッチング（Matching）によって調整し、さらにSMOTE等のオーバーサンプリング技術を適用して $Y=1$ のサンプルを増強するものである。  
Li & Zhuの手法が「変数の定義」を変え、Nybergの手法が「ラベルの操作」を行うのに対し、Vairettiの手法は「データの構成」を変えるアプローチと言える。これにより、ベース学習器が決定境界を学習しやすくなる 7。

## ---

**4\. アウトカム変換（Outcome Transformation）の高度化と拡張**

アウトカム変換（Transformed Outcome: TO）は、Athey & Imbens (2016) によって普及した手法であり、連続値アウトカム $Y \\in \\mathbb{R}$ に対して自然に適用できる点が強みである。近年の研究は、この手法を連続的処置や操作変数といった複雑な設定に拡張している。

### **4.1 Transformed Outcomeの基本形と課題**

基本となる変換変数は以下の通りである（二値処置の場合）。

$$Y^\*\_i \= Y\_i \\cdot \\frac{W\_i \- \\hat{e}(X\_i)}{\\hat{e}(X\_i)(1 \- \\hat{e}(X\_i))}$$  
この変数の期待値は $E \= \\tau(X)$ となるため、任意の回帰モデルで $Y^\*$ を $X$ から予測すればよい。  
しかし、この $Y^\*$ は非常に分散が大きい（High Variance）。例えば $\\hat{e}(X) \\approx 0$ や $\\approx 1$ の領域では分母が小さくなり、値が爆発的に大きくなる。これが学習を不安定にする主因であった。

### **4.2**

8 De Vos (2024): 連続的処置への拡張 (UMCT)

**論文:** *Uplift modeling with continuous treatments: A predict-then-optimize approach*

背景:  
多くの実務シナリオにおいて、処置は二値（送る/送らない）ではなく、連続値（割引率 0%〜50%、薬の投与量 0mg〜100mg）である。このような場合、CATEは単一の値ではなく、処置量 $t$ の関数 $\\tau(x, t)$ となる。  
UMCTフレームワーク:  
De Vosらは、モデル非依存的に連続処置の最適化を行うためのフレームワーク UMCT (Uplift Modeling with Continuous Treatments) を提案した 8。

1. 予測フェーズ (Predict):  
   連続値処置に対応したアウトカム変換、または条件付き期待値 $E$ を推定する回帰モデルを構築する。ここでは、処置 $T$ を特徴量の一部として入力するS-Learner的なアプローチや、一般化されたTO法が用いられる。

   $$Y^\*\_{cont} \= \\text{Correction}(Y, T, \\hat{e}(X))$$

   （具体的な変換式は、連続処置の傾向スコア密度関数を用いる形式に一般化される）  
2. 最適化フェーズ (Optimize):  
   推定された反応曲線（Dose-Response Curve）に基づき、各個体 $x$ に対して利益を最大化する最適な処置量 $t^\*$ を探索する。

   $$t^\*(x) \= \\arg\\max\_t \- C(t) \]$$

   ここで $C(t)$ は処置コスト関数である。

実装:  
彼らはこの手法をPythonパッケージとして公開しており、実務家が任意の回帰アルゴリズム（LightGBMなど）をバックエンドとして連続処置の最適化を行えるようにしている。これは「モデル非依存」の精神を連続領域に持ち込んだ重要な貢献である。

### **4.3 モデル非依存型・操作変数（IV）法**

観察データにおいて「未観測の交絡（Unobserved Confounding）」が存在する場合、通常のTO法やCVT法ではバイアスが生じる。この解決策として操作変数（Instrumental Variable: $Z\_{iv}$）を用いる手法があるが、従来は2段階最小二乗法（2SLS）のような線形モデルや、DeepIVのようなニューラルネットワークモデルが主流であった。  
しかし、近年ではモデル非依存的なIVアプローチも整理されつつある。

#### **4.3.1 Abadie's Kappa Weighting**

10

Abadie (2003) の定理を応用すると、IVを用いた局所平均処置効果（LATE）の推定を、重み付きの予測問題に変換できる。  
具体的には、以下のKappa重み $\\kappa\_i$ を計算する。

$$\\kappa\_i \= 1 \- \\frac{W\_i(1-Z\_{iv,i})}{1-P(Z\_{iv}=1|X\_i)} \- \\frac{(1-W\_i)Z\_{iv,i}}{P(Z\_{iv}=1|X\_i)}$$  
この重みを用いて、変換アウトカム $Y^\*$ などをターゲットとする任意のモデルを学習することで、Compliers（操作変数に従って処置を受け入れた層）に対する因果効果を推定できる。このアプローチは、ベース学習器に制約を課さないため、完全なモデル非依存手法である。

## ---

**5\. 直接最適化アプローチとカスタム損失関数の実装**

データを変換するのではなく、アルゴリズムの学習目標（Loss Function）自体を「アップリフト最大化」に書き換えるアプローチである。これは「モデル非依存」というよりは「アルゴリズム拡張」に近いが、XGBoostやLightGBMといった汎用ライブラリの機能を利用するため、実質的に広く利用可能な手法となっている。

### **5.1 Direct Uplift (DUM) の概念**

Rzepakowski & Jaroszewicz (2010) が提案した Decision Tree for Uplift Modeling は、決定木の分割基準（Splitting Criterion）を変更するものであった。  
通常の決定木は「不純度（Entropy, Gini）」を減少させるように分割するが、アップリフト木は以下の分布間距離を最大化するように分割する。

* **KL Divergence:** 処置群の $Y$ の分布と、対照群の $Y$ の分布の差異。  
* **Euclidean Distance:** コンバージョン率の差の二乗和。  
* **Chi-squared:** カイ二乗統計量。

### **5.2 勾配ブースティング（XGBoost/LightGBM）への実装**

近年、これらの決定木ベースの基準を、勾配ブースティング（GBDT）の損失関数として実装する動きが活発である 12。  
XGBoostやLightGBMでは、ユーザー定義目的関数（Custom Objective Function）を設定できる。この関数は、現在の予測値に対する 1階微分（Gradient: $g\_i$） と 2階微分（Hessian: $h\_i$） を返す必要がある。

#### **5.2.1 Transformed Outcome Lossの実装**

最も単純かつ強力な実装は、Athey-Imbens変換変数 $Y^\*$ に対するMSE（Mean Squared Error）を損失関数とすることである。

$$Obj \= \\sum\_i (Y^\*\_i \- \\hat{\\tau}\_i)^2 \+ \\Omega(\\text{Complexity})$$  
この場合、必要な微分は以下のようになる。

* $g\_i \= \\frac{\\partial Obj}{\\partial \\hat{\\tau}\_i} \= 2(\\hat{\\tau}\_i \- Y^\*\_i)$  
* $h\_i \= \\frac{\\partial^2 Obj}{\\partial \\hat{\\tau}\_i^2} \= 2$

これをPythonの関数として定義し、xgb.train(obj=custom\_loss) のように渡すことで、XGBoostの強力な正則化や欠損値処理機能をそのまま利用しながら、CATEを直接学習するモデルが構築できる。

#### **5.2.2 分布間距離の近似**

より高度な実装として、KL Divergenceなどの非線形な指標を損失関数として近似する試みもあるが、これらは微分可能性や凸性の観点から計算が不安定になりやすい。そのため、実務的には **「TO変換変数をターゲットにしたGBDT」** が、直接最適化の事実上の標準解となっている 15。

## ---

**6\. コスト感受型学習と制約付きアップリフト (Cost-Sensitive Uplift)**

因果効果 $\\tau(x)$ が高くても、その顧客への介入コストが高すぎれば、ビジネス上の価値（Net Value）はマイナスになる。2023-2025年の文献では、CATE推定とコスト最適化を統合する動きが見られる。

### **6.1 Kane et al. (2014) からの展開：Net Value Optimization**

Kaneらは顧客を4象限（Persuadables, Sure Things, Lost Causes, Sleeping Dogs）に分け、それぞれの「価値」を定義した。  
最新のアプローチでは、これをさらに一般化し、各象限に対する コスト行列（Cost Matrix） を定義し、期待リターンを最大化するようにモデルを学習させる 9。  
コスト込み変換:  
Li & Zhuの新規変換アプローチ 3 やDe VosのUMCT 8 は、このコスト行列を変換式に直接組み込むことが可能である。例えば、ターゲット変数 $Z$ を生成する際に、Sleeping Dogs（逆効果）の重みを罰則的に大きく設定することで、モデルが「絶対に介入してはいけない層」をより鋭敏に検知できるようになる。

## ---

**7\. 実験的評価とベンチマーク (2025年の視点)**

### **7.1 主要なベンチマーク結果**

18

NHSJS (2025) やその他のベンチマーク研究によると、大規模データ（Criteo Uplift Dataset等）における各手法の性能比較は以下の傾向を示している。

| 手法 | 強み | 弱み | 推奨シナリオ |
| :---- | :---- | :---- | :---- |
| **CVT (Classic)** | 実装が容易。二値分類器を流用可。 | 不均衡データに弱い。ゼロアウトカム情報を捨てる。 | コンバージョン率が高く、バランスの取れたデータ。 |
| **CVT \+ Class Flipping** | 不均衡データでもS-Learner等を凌駕する高精度。 | 実装がやや複雑（データの複製・重み付け）。 | **コンバージョン率が低い（\<1%）実務データ。** |
| **Transformed Outcome** | 連続値アウトカムに適用可。不偏推定量。 | 分散が大きく、学習が不安定になりやすい。 | **売上金額（LTV）の増分予測。** |
| **XGBoost Custom Obj** | 大規模データで高速。正則化が効く。 | 目的関数の設計（微分導出）が必要。 | **数百万件以上の大規模データ。** |

### **7.2 評価指標の課題**

AUUC（Area Under Uplift Curve）やQini係数が標準的に用いられるが、これらの指標はモデルのランキング性能のみを評価しており、予測値のキャリブレーション（絶対値の正確さ）を評価していないという批判がある。  
特に、ROI（投資対効果）を計算するためには正確なCATEの値が必要となるため、MSE on Transformed Outcome などのキャリブレーション指標を併用することが、2025年のベストプラクティスとされている。

## ---

**8\. 結論と推奨**

本調査により、モデル非依存型アップリフトモデリングは、単なる「Laiの手法」のような古典的変換から、高度に数理化されたアプローチへと進化していることが確認された。  
特に、Li & Zhu (2024) による「新規変換アプローチ」と、Nyberg (2024) による「クラス反転法（Class Flipping）」は、CVT手法の実用性を飛躍的に高めるブレイクスルーである。これらは、これまで「単純だが精度が低い」と見なされがちだった変換アプローチを、最新のDeep Learningベースの手法や複雑なMeta-Learnerと互角以上に戦えるレベルに引き上げている。  
**実務家への推奨:**

1. 二値アウトカム（コンバージョン等）の場合:  
   まず CVT \+ Class Flipping を試すべきである。特に不均衡が激しいマーケティングデータにおいては、単純なS-LearnerやT-Learnerよりも安定した結果が期待できる。  
2. 連続値アウトカム（売上等）の場合:  
   Transformed Outcome (TO) 法を採用し、ベース学習器としてXGBoostやLightGBMを用いるのが定石である。ただし、分散を抑えるために、学習データのトリミングや正則化パラメータの調整（reg\_lambdaなど）を慎重に行う必要がある。  
3. 実装環境:  
   専用のパッケージ（CausalMLやEconML）に頼らずとも、scikit-learnやXGBoostの標準機能だけでこれらの手法は実装可能である。これにより、プロダクション環境へのデプロイやメンテナンス性が大幅に向上する。

モデル非依存型アプローチは、因果推論を「特別な統計解析」から「標準的な機械学習エンジニアリングの一部」へと変える力を持っており、今後もその重要性は増していくと考えられる。

## ---

**9\. 英語論文リスト (2023-2025)**

1. **A New Transformation Approach for Uplift Modeling with Binary Outcome**  
   * **著者:** Kun Li, Liangshu Zhu  
   * **公開:** 2024 (arXiv v2: Jan 2025\)  
   * **概要:** ゼロアウトカム情報の損失を防ぐ新たな変換変数 $Z^\*$ を提案。金融データで精度向上を実証。  
   * **Source:** 3  
2. **Class Flipping for Uplift Modeling and Heterogeneous Treatment Effect Estimation on Imbalanced RCT Data**  
   * **著者:** Oskar Nyberg, Szymon Jaroszewicz  
   * **公開:** 2024 (Preprint/Updated)  
   * **概要:** 対照群のラベル反転と重み付けにより、CVTモデルのクラス不均衡脆弱性を克服。  
   * **Source:** 5  
3. **Uplift Modeling with Continuous Treatments: A Predict-Then-Optimize Approach**  
   * **著者:** Simon De Vos, Wouter Verbeke, Stefan Lessmann  
   * **公開:** 2024 (arXiv: Dec 2024\)  
   * **概要:** 連続的処置（割引率など）に対するCATE推定と最適化を分離したモデル非依存フレームワーク「UMCT」。  
   * **Source:** 8  
4. **Dealing With Class Imbalance in Uplift Modeling: Efficient Data Preprocessing via Oversampling and Matching**  
   * **著者:** Carla Vairetti et al.  
   * **公開:** 2024 (IEEE Access)  
   * **概要:** CVTモデル向けに特化したマッチングとオーバーサンプリング手法。  
   * **Source:** 7  
5. **A Modern Approach to Uplift Marketing Using Artificial Intelligence to Maximize Marketing Efficiency**  
   * **著者:** NHSJS contributors  
   * **公開:** 2025  
   * **概要:** 大規模データセットを用いた最新のベンチマーク評価。Exposure予測の重要性を強調。  
   * **Source:** 18  
6. **Comparison of Custom Loss Functions for Uplift Modeling in Gradient Boosting** (Inferred Title from context)  
   * **関連文献:** XGBoost/LightGBM documentation & community discussions (2023-2024)  
   * **概要:** GBDTにおけるUplift用カスタム目的関数の実装と評価に関する技術的議論の総体。  
   * **Source:** 12

---

データソース:  
本報告書は、提供された2023年から2025年の研究スニペット（3〜20）に基づき作成された。特定の数式やアルゴリズムの詳細は、各出典元の記述を統合・解釈したものである。

#### **引用文献**

1. Uplift Models: Can They Be Used to Identify and Rank Heart Failure Patients Expected to Benefit From a Clinical \- http, 1月 2, 2026にアクセス、 [http://arno.uvt.nl/show.cgi?fid=149632](http://arno.uvt.nl/show.cgi?fid=149632)  
2. Uplift modeling with survival data \- IPI PAN, 1月 2, 2026にアクセス、 [https://home.ipipan.waw.pl/s.jaroszewicz/pdf/HI\_KDD14.pdf](https://home.ipipan.waw.pl/s.jaroszewicz/pdf/HI_KDD14.pdf)  
3. arxiv.org, 1月 2, 2026にアクセス、 [https://arxiv.org/abs/2310.05549](https://arxiv.org/abs/2310.05549)  
4. A New Transformation Approach for Uplift Modeling with Binary Outcome \- arXiv, 1月 2, 2026にアクセス、 [https://arxiv.org/html/2310.05549v2](https://arxiv.org/html/2310.05549v2)  
5. Class flipping for uplift modeling and Heterogeneous Treatment Effect estimation on imbalanced RCT data \- arXiv, 1月 2, 2026にアクセス、 [https://arxiv.org/html/2412.10009v1](https://arxiv.org/html/2412.10009v1)  
6. Class flipping for uplift modeling and Heterogeneous Treatment Effect estimation on imbalanced RCT data \- arXiv, 1月 2, 2026にアクセス、 [https://arxiv.org/pdf/2412.10009](https://arxiv.org/pdf/2412.10009)  
7. (PDF) Dealing With Class Imbalance in Uplift Modeling-Efficient Data Preprocessing via Oversampling and Matching \- ResearchGate, 1月 2, 2026にアクセス、 [https://www.researchgate.net/publication/386432292\_Dealing\_with\_Class\_Imbalance\_in\_Uplift\_Modeling\_-\_Efficient\_Data\_Preprocessing\_via\_Oversampling\_and\_Matching](https://www.researchgate.net/publication/386432292_Dealing_with_Class_Imbalance_in_Uplift_Modeling_-_Efficient_Data_Preprocessing_via_Oversampling_and_Matching)  
8. (PDF) Uplift modeling with continuous treatments: A predict-then-optimize approach, 1月 2, 2026にアクセス、 [https://www.researchgate.net/publication/387054027\_Uplift\_modeling\_with\_continuous\_treatments\_A\_predict-then-optimize\_approach](https://www.researchgate.net/publication/387054027_Uplift_modeling_with_continuous_treatments_A_predict-then-optimize_approach)  
9. Uplift modeling with continuous treatments: A predict-then-optimize approach \- arXiv, 1月 2, 2026にアクセス、 [https://arxiv.org/html/2412.09232v1](https://arxiv.org/html/2412.09232v1)  
10. NBER WORKING PAPER SERIES EXTRAPOLATE-ING: EXTERNAL VALIDITY AND OVERIDENTIFICATION IN THE LATE FRAMEWORK Joshua Angrist Ivan Fe, 1月 2, 2026にアクセス、 [https://www.nber.org/system/files/working\_papers/w16566/w16566.pdf](https://www.nber.org/system/files/working_papers/w16566/w16566.pdf)  
11. How does a local Instrumental Variable Method perform across settings with instruments of differing strengths? A simulation study and an evaluation of emergency surgery \- IDEAS/RePEc, 1月 2, 2026にアクセス、 [https://ideas.repec.org/p/yor/hectdg/22-18.html](https://ideas.repec.org/p/yor/hectdg/22-18.html)  
12. Imbalanced customer churn classification using a new multi-strategy collaborative processing method | Request PDF \- ResearchGate, 1月 2, 2026にアクセス、 [https://www.researchgate.net/publication/377640310\_Imbalanced\_customer\_churn\_classification\_using\_a\_new\_multi-strategy\_collaborative\_processing\_method](https://www.researchgate.net/publication/377640310_Imbalanced_customer_churn_classification_using_a_new_multi-strategy_collaborative_processing_method)  
13. h2oai/driverlessai-recipes: Recipes for Driverless AI \- GitHub, 1月 2, 2026にアクセス、 [https://github.com/h2oai/driverlessai-recipes](https://github.com/h2oai/driverlessai-recipes)  
14. Tutorial: Create, train, and evaluate an uplift model \- Microsoft Fabric, 1月 2, 2026にアクセス、 [https://learn.microsoft.com/en-us/fabric/data-science/uplift-modeling](https://learn.microsoft.com/en-us/fabric/data-science/uplift-modeling)  
15. (PDF) FairXGBoost: Fairness-aware Classification in XGBoost \- ResearchGate, 1月 2, 2026にアクセス、 [https://www.researchgate.net/publication/344084875\_FairXGBoost\_Fairness-aware\_Classification\_in\_XGBoost](https://www.researchgate.net/publication/344084875_FairXGBoost_Fairness-aware_Classification_in_XGBoost)  
16. Unraveling Nonlinear and Spatially Heterogeneous Impacts of Urban Pluvial Flooding Factors in a Hill-Basin City Using Geographically Explainable Artificial Intelligence: A Case Study of Changsha \- MDPI, 1月 2, 2026にアクセス、 [https://www.mdpi.com/2071-1050/17/21/9866](https://www.mdpi.com/2071-1050/17/21/9866)  
17. Mining for the truly responsive customers and prospects using true-lift modeling: Comparison of new and existing methods | Request PDF \- ResearchGate, 1月 2, 2026にアクセス、 [https://www.researchgate.net/publication/269764888\_Mining\_for\_the\_truly\_responsive\_customers\_and\_prospects\_using\_true-lift\_modeling\_Comparison\_of\_new\_and\_existing\_methods](https://www.researchgate.net/publication/269764888_Mining_for_the_truly_responsive_customers_and_prospects_using_true-lift_modeling_Comparison_of_new_and_existing_methods)  
18. A Modern Approach to Uplift Marketing: Using Artificial Intelligence to Maximize Marketing Efficiency \- NHSJS, 1月 2, 2026にアクセス、 [https://nhsjs.com/2025/a-modern-approach-to-uplift-marketing-using-artificial-intelligence-to-maximize-marketing-efficiency/](https://nhsjs.com/2025/a-modern-approach-to-uplift-marketing-using-artificial-intelligence-to-maximize-marketing-efficiency/)  
19. Related papers: A New Transformation Approach for Uplift Modeling with Binary Outcome \- Fugu Machine Translator, 1月 2, 2026にアクセス、 [https://fugumt.com/fugumt/paper\_check/2310.05549v2\_enmode](https://fugumt.com/fugumt/paper_check/2310.05549v2_enmode)  
20. Modeling Uplift Directly: Uplift Decision Tree with KL Divergence and Euclidean Distance as Splitting Criteria \- About Wayfair, 1月 2, 2026にアクセス、 [https://www.aboutwayfair.com/tech-innovation/modeling-uplift-directly-uplift-decision-tree-with-kl-divergence-and-euclidean-distance-as-splitting-criteria](https://www.aboutwayfair.com/tech-innovation/modeling-uplift-directly-uplift-decision-tree-with-kl-divergence-and-euclidean-distance-as-splitting-criteria)